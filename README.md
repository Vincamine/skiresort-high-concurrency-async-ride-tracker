‚öôÔ∏è Technical Overview of the Ski Data Processing System

This system is designed to handle high-throughput, low-latency processing of skier lift ride data using a modular and scalable architecture. It supports both large-scale data ingestion (POST) and efficient query retrieval (GET), optimized for concurrent workloads.

‚∏ª

üß± Architecture Components
	‚Ä¢	Client1 / Client2: Generate and send up to 200,000 lift ride events using multithreaded API clients. Client2 additionally logs latency, status, and throughput metrics.
	‚Ä¢	Server (Servlet-based): Handles RESTful POST/GET requests. Writes go through RabbitMQ; reads are served via Redis cache.
	‚Ä¢	RabbitMQ (Message Queue): Asynchronous decoupling between ingestion and processing layers.
	‚Ä¢	Consumer: Pulls messages from RabbitMQ, parses data, and stores results in Redis using a thread pool and asynchronous processing.

‚∏ª

üõ†Ô∏è Core Technologies & Techniques
	‚Ä¢	Concurrency:
	‚Ä¢	ExecutorService and CompletableFuture ensure scalable multithreading.
	‚Ä¢	ConcurrentHashMap for safe, shared-memory operations.

	‚Ä¢	Redis:
	‚Ä¢	Used as an in-memory cache to reduce latency and offload read-heavy traffic.
	‚Ä¢	Structures: Hashes (per-skier stats), Sets (unique skiers), optimized with precomputed fields and TTLs.

	‚Ä¢	RabbitMQ:
	‚Ä¢	Enables high-throughput message queuing between API and consumer layers.
	‚Ä¢	Custom channel pooling to reduce connection overhead.

	‚Ä¢	Performance Testing:
	‚Ä¢	JMeter used for simulating 128 threads √ó 500 iterations (64,000+ GET requests).
	‚Ä¢	System supports ~2,965 requests/sec with <30ms average response time.

‚∏ª

üìà Optimization Strategies
	‚Ä¢	Redis Read Replicas: Offload heavy read traffic.
	‚Ä¢	Redis Cluster: Enables automatic key sharding across multiple nodes.
	‚Ä¢	Hot Key Sharding: Hash-based key splitting for load balancing.
	‚Ä¢	Hot/Cold Data Separation: Redis used for active (‚Äúhot‚Äù) data; MySQL planned for persistent storage of inactive (‚Äúcold‚Äù) data.
